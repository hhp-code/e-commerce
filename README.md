# K6 부하테스트 & 장애대응 문서

## K6 부하 테스트 개요

### 테스트 환경
- **CPU**: 4G
- **메모리**: 8G

### 테스트 대상
- 주문 결제 API
- 주문 생성 API
- 주문 조회 API

### 테스트 목적
- 시스템의 최대 처리 용량 파악
- 응답 시간 및 처리량 측정
- 병목 지점 식별
- 200TPS 부하에 대한 안전성 보장

### 테스트 시나리오
1. 부하 테스트
2. 내구성 테스트
3. 스트레스 테스트
4. 최고 부하 테스트 (스파이크 테스트)

## 테스트 실행 문제 및 해결 과정
![스크린샷 2024-08-19 22 41 09](https://github.com/user-attachments/assets/6fc7f7e4-da31-4ce2-85a3-4bbb303ec27f)
![스크린샷 2024-08-20 10 17 59](https://github.com/user-attachments/assets/47d6b80e-4941-46b1-bebb-e34885547952)

1. 초기 실행 시 데드락 발생
   - 원인: 'User' 도메인 변경에 동시성 문제
   - 해결: 락 적용 후 재시도

2. 하이버네이트 관련 예외 발생
   - IllegalStateException 및 NullPointerException 발생
   - 원인: 하이버네이트의 스레드 안전성 문제

3. 데드락 해결을 위한 설계 변경
   - 주문->유저 참조 방식 변경
   - 컨트롤러 스펙변경을 통해 유저번호, 주문번호를 통한 변경 방식 도입

4. 서버 스펙 업그레이드
   - 2CPU 4G에서 4CPU 8G로 변경

5. 도커 컴포즈 도입
   - 단일 도커파일 사용에서 도커 컴포즈로 전환

## 테스트 결과 분석
![스크린샷 2024-08-20 12 18 03](https://github.com/user-attachments/assets/011747eb-fab6-4a33-a9fd-f4a4f2b2174a)

### 응답 시간
- 평균: 10.4ms
- 중앙값: 7.48ms
- 최소: 990μs
- 최대: 757.78ms
- 90번째 백분위수: 20.42ms
- 95번째 백분위수: 26.15ms

### 요청 처리량
- 총 처리 요청: 458,616
- 초당 요청 처리량: 141.457939/s

### 오류율
- http_req_failed: 0.00%

### 추가 정보
- 최대 가상 사용자 수: 550명
- 테스트 실행 시간: 54분 2.1초
- 총 반복 횟수: 114,654회


## 분석
1. **성능 목표 달성**:
   - 목표했던 200 TPS에 근접한 141 TPS를 달성했습니다.

2. **시스템 안정성**:
   - 오류율 0%
   - 평균 응답 시간 10.4ms

3. **확장성**:
   - 최대 550명의 동시 사용자를 처리할 수 있었습니다.

4. **예상 일일 사용자 수**:
   - 약 30만~35만 명의 일일 활성 사용자(DAU)를 안정적으로 지원할 수 있을 것으로 추정됩니다.
   - 이는 사용자당 평균 30개의 요청을 한다고 가정했을 때의 보수적인 추정치입니다.

## 개선
#### 테스트 스크립트 수정 및 추가
- 테스트 시나리오 200TPS 이상으로 요청

![스크린샷 2024-08-20 12 18 03](https://github.com/user-attachments/assets/f298eb26-68c8-46fe-8bd1-b670c5c53813)
1. **성능 목표 달성**:
   - 목표했던 200 TPS를 크게 초과하여 580.496062 TPS 달성

2. **시스템 안정성**:
   - 오류율 0%
   - 평균 응답 시간 6.44ms

3. **확장성**:
   - 최대 300명의 동시 사용자를 처리할 수 있었습니다.
   - 이는 실제 운영 환경에서 대규모 트래픽을 효과적으로 감당할 수 있음을 의미합니다.

4. **예상 일일 사용자 수**:
   - 약 125만 명의 일일 활성 사용자(DAU)를 안정적으로 지원할 수 있을 것으로 추정됩니다.
   - 이는 사용자당 평균 50개의 요청을 한다고 가정했을 때의 계산 결과입니다.

5. **추가 성능 지표**:
   - 데이터 처리량: 수신 125 kB/s, 송신 89 kB/s
   - 95번째 백분위수 응답 시간: 8.36ms

## 장애대응
현재 테스트상 장애가 발생하지 않으므로, 가상 장애대응 문서를 작성합니다.

## 장애대응 문서

### 장애탐지
- **모니터링 시스템 구축**: Prometheus와 Grafana를 활용하여 실시간 시스템 모니터링 구축
- **알림 설정**: CPU 사용률, 메모리 사용량, 응답 시간 등 주요 지표에 대한 임계값 설정 및 알림 구성
-

![스크린샷 2024-08-20 13 06 34](https://github.com/user-attachments/assets/b5ad09c5-5cae-4a79-8e24-0e640c71de97)
![스크린샷 2024-08-20 13 11 50](https://github.com/user-attachments/assets/7f7f8743-e2cc-44a5-be0d-f9d983b55e2f)
### 장애공지
- **내부 공지**: Slack 채널을 통한 개발팀 및 운영팀 즉시 알림
- **외부 공지**: 사용자 대상 공지 페이지 및 푸시 알림 시스템 구축
- **공지 템플릿**: 장애 유형별 표준화된 공지 템플릿 준비

### 장애전파
- **에스컬레이션 프로세스**: 장애 심각도에 따른 단계별 보고 체계 수립
  - 1단계: 당직 엔지니어 또는 운영팀
  - 2단계: 서비스 담당 개발팀
  - 3단계: 경영진 또는 상급 조직
  - 에스컬레이션 기준: 시간기반, 영향도 기반, 복잡도 기반
- **비상 연락망**: 주요 담당자 및 의사결정권자 연락처 목록 관리
- **상황 공유 플랫폼**: Jira 또는 전용 대시보드를 통한 실시간 상황 공유

### 장애복구
- **롤백 절차**:
   - 이전 안정 버전으로의 신속한 롤백 프로세스 문서화
   - 데이터베이스 롤백 절차 및 데이터 정합성 확인 방법 정립
- **핫픽스 배포**:
   - CI/CD 파이프라인을 통한 신속한 핫픽스 배포 체계 구축
   - 코드 리뷰 및 테스트 간소화 프로세스 마련

### 장애 후속조치
- **사후 분석 회의(Post-mortem)**: 장애 원인, 대응 과정, 개선점 논의
- **재발 방지 대책**: 기술적/프로세스적 개선 사항 도출 및 이행 계획 수립
- **문서화**: 장애 보고서 작성 및 지식베이스 구축

### 장애지표 활용
- **KPI 설정**: MTTR(평균 복구 시간), MTBF(평균 장애 간격) 등 주요 지표 선정\
  - MTTR: 장애 발생부터 복구까지 걸리는 평균 시간
  - MTBF: 장애 발생 간격의 평균 시간
- **트렌드 분석**: 장애 유형, 빈도, 영향도 등에 대한 정기적인 분석 실시
- **성과 측정**: 장애 대응 프로세스 개선에 따른 효과 측정 및 보고

### 훈련 및 시뮬레이션
- **정기적인 모의 훈련**: 분기별 장애 대응 시뮬레이션 실시
- **역할 교육**: 팀원별 역할 및 책임에 대한 정기적인 교육 진행

### 커뮤니케이션 전략
- **대내외 소통 채널**: 고객 지원센터, 소셜 미디어, 이메일 등 다양한 채널 활용
- **투명성 확보**: 장애 상황 및 복구 진행 상황에 대한 투명한 공개 원칙 수립

#### 장애대응 예시

##### 장애대응 문서 예시

 1. 장애 개요
- **장애 발생 일시**: 2023년 5월 15일 14:30 KST
- **장애 종료 일시**: 2023년 5월 15일 16:45 KST
- **장애 지속 시간**: 2시간 15분
- **영향 범위**: 전체 사용자의 결제 서비스 불가
- **장애 유형**: 데이터베이스 연결 오류

 2. 장애 탐지
- **탐지 방법**: Grafana 모니터링 알림
- **최초 탐지 시간**: 2023년 5월 15일 14:32 KST
- **탐지 내용**: 데이터베이스 연결 시도 실패 로그 급증
- **서킷브레이커**: Reslience4J를 통한 서킷브레이커 동작 확인
- **슬로우 쿼리**: my.cnf 활성화를 통해 Slow Query Log를 통한 쿼리 성능 저하 확인

 3. 장애 전파
- **내부 공유**: Slack #장애대응 채널에 즉시 공유
- **고객 공지**: 웹사이트 및 모바일 앱에 장애 안내 배너 게시

 4. 대응 조치
- 14:35 - 데이터베이스 서버 상태 확인
- 14:40 - 데이터베이스 연결 풀 재설정 시도
- 15:00 - 데이터베이스 서버 재시작
- 15:30 - 백업 데이터베이스로 전환
- 16:30 - 서비스 정상화 확인

 5. 원인 분석
- 주 데이터베이스 서버의 메모리 누수로 인한 연결 처리 불가
- 연결 풀 관리 로직의 버그로 인한 연결 해제 실패

 6. 재발 방지 대책
- 데이터베이스 서버 메모리 모니터링 강화
- 연결 풀 관리 로직 개선 및 테스트 강화
- 자동 장애 복구 시스템 구축 계획 수립

 7. 후속 조치
- 고객 대상 사과문 발송 및 보상 정책 수립
- 개발팀 대상 장애 원인 및 대응 과정 공유 세션 진행
- 운영 프로세스 개선을 위한 태스크포스 구성

 8. 교훈 및 개선점
- 백업 시스템으로의 전환 시간 단축 필요
- 주요 시스템 컴포넌트에 대한 정기적인 스트레스 테스트 도입
- 장애 상황 시뮬레이션 훈련 정례화

